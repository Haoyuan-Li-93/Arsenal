{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import time \n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import psana\n",
    "\n",
    "sys.path.append('/reg/neh/home5/haoyuan/Documents/my_repos/Arsenal')\n",
    "import arsenal\n",
    "import arsenal.lcls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the parameters to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cxi file is located at /reg/d/psdm/amo/amox26916/scratch/haoyuan/psocake/r0085/amox26916_0085.cxi\n",
      "There are 16823 patterns in this run in total.\n",
      "Processing results will be saved to folder ../output/.\n"
     ]
    }
   ],
   "source": [
    "exp_line = 'amo'\n",
    "exp_name = 'amox26916'\n",
    "user_name = 'haoyuan'\n",
    "\n",
    "#get a tag\n",
    "tag = 'hits'\n",
    "\n",
    "process_stage = 'scratch'\n",
    "\n",
    "run_num = 85\n",
    "det_name = 'pnccdFront'\n",
    "\n",
    "# Construct the file address of the corresponding cxi file\n",
    "file_name = '/reg/d/psdm/{}/{}/{}/{}/psocake/r{:0>4d}/{}_{:0>4d}.cxi'.format(exp_line, \n",
    "                                                                             exp_name,\n",
    "                                                                             process_stage,\n",
    "                                                                             user_name,\n",
    "                                                                             run_num,\n",
    "                                                                             exp_name,\n",
    "                                                                             run_num)\n",
    "print(\"The cxi file is located at {}\".format(file_name))\n",
    "\n",
    "# The numpy array file containing indexes to inspect\n",
    "index_to_process = np.load('../output/selected_global_index.npy')\n",
    "# Get pattern number\n",
    "pattern_num = len(index_to_process)\n",
    "print(\"There are {} patterns in this run in total.\".format(pattern_num))\n",
    "\n",
    "# Specify the output address\n",
    "output_address = '../output/'\n",
    "print(\"Processing results will be saved to folder {}.\".format(output_address))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intialize the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The photon wave length is 7.28753167555e-10 m.\n"
     ]
    }
   ],
   "source": [
    "# Get data source\n",
    "ds = psana.DataSource('exp={}:run={}:idx'.format(exp_name, run_num))\n",
    "run = ds.runs().next()    \n",
    "env = ds.env()\n",
    "times = run.times()\n",
    "evt = run.event(times[0])\n",
    "\n",
    "# Get photon energy\n",
    "with  h5.File(file_name, 'r') as h5file:\n",
    "    holder = h5file['/LCLS/photon_wavelength_A'].value\n",
    "    # convert to meter\n",
    "    photon_wavelength = holder[0] / (10**10)\n",
    "    photon_energy = arsenal.radial.get_energy(wavelength=photon_wavelength)\n",
    "print(\"The photon wave length is {} m.\".format(photon_wavelength))\n",
    "\n",
    "# Get detector\n",
    "det = psana.Detector('pnccdFront', env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide the index list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are roughly 336 batches to process.\n"
     ]
    }
   ],
   "source": [
    "sub_lists_num = index_to_process.shape[0] // 50\n",
    "print(\"There are roughly {} batches to process.\".format(sub_lists_num))\n",
    "\n",
    "# Get sublists \n",
    "sub_lists = np.array_split(ary=index_to_process,indices_or_sections=sub_lists_num, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the statistics\n",
    "The strategy is simple. \n",
    "1. One first define a holder for min, max, sum, sum of the square for each of the four statistics.\n",
    "2. Construct mean from sum\n",
    "3. Construct std from mean and sum of the square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 8.15 seconds to process 51 patterns.\n"
     ]
    }
   ],
   "source": [
    "# For the first sublist\n",
    "data_holder = np.zeros((sub_lists[0].shape[0], 4, 512, 512))\n",
    "\n",
    "tic = time.time()\n",
    "counter = 0\n",
    "for idx in sub_lists[0]:\n",
    "    \n",
    "    # Get the pattern\n",
    "    data_holder[counter] = arsenal.lcls.get_pattern_stack(detector=det, exp_run=run, event_id=idx)\n",
    "    # Update the local index\n",
    "    counter += 1\n",
    "    \n",
    "toc = time.time()\n",
    "print(\"It takes {:.2f} seconds to process {} patterns.\".format(toc-tic, sub_lists[0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_holder = np.min(data_holder, axis=0)\n",
    "max_holder = np.max(data_holder, axis=0)\n",
    "sum_holder = np.sum(data_holder, axis=0)\n",
    "square_sum_holder = np.sum(np.square(data_holder), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 5.75 seconds to process 51 patterns.\n",
      "Finishes processing batch 1\n",
      "It takes 5.64 seconds to process 51 patterns.\n",
      "Finishes processing batch 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-20111b82ec53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Get the pattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdata_holder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marsenal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pattern_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Update the local index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/reg/neh/home5/haoyuan/Documents/my_repos/Arsenal/arsenal/lcls.pyc\u001b[0m in \u001b[0;36mget_pattern_stack\u001b[0;34m(detector, exp_run, event_id)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mevt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mpattern_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpattern_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/reg/g/psdm/sw/conda/inst/miniconda2-prod-rhel7/envs/ana-1.3.58/lib/python2.7/site-packages/Detector/AreaDetector.pyc\u001b[0m in \u001b[0;36mcalib\u001b[0;34m(self, evt, cmpars, mbits, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cspad2x2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo2x1ToData2x2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert to DAQ shape for cspad2x2 ->(185, 388, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon_mode_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmpars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cspad2x2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata2x2ToTwo2x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert to Natural shape for cspad2x2 ->(2, 185, 388)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/reg/g/psdm/sw/conda/inst/miniconda2-prod-rhel7/envs/ana-1.3.58/lib/python2.7/site-packages/Detector/AreaDetector.pyc\u001b[0m in \u001b[0;36mcommon_mode_apply\u001b[0;34m(self, par, nda, cmpars, **kwargs)\u001b[0m\n\u001b[1;32m    930\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon_mode_double_v0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon_mode_float_v0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0mnda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get a counter for different batches\n",
    "batch_counter = 1\n",
    "\n",
    "for sub_list in sub_lists[1:]:\n",
    "    \n",
    "    # For the specific sublist\n",
    "    data_holder = np.zeros((sub_list.shape[0], 4, 512, 512))\n",
    "\n",
    "    tic = time.time()\n",
    "    counter = 0\n",
    "    for idx in sub_list:\n",
    "\n",
    "        # Get the pattern\n",
    "        data_holder[counter] = arsenal.lcls.get_pattern_stack(detector=det, exp_run=run, event_id=idx)\n",
    "        # Update the local index\n",
    "        counter += 1\n",
    "\n",
    "    toc = time.time()\n",
    "    print(\"It takes {:.2f} seconds to process {} patterns.\".format(toc-tic, sub_lists[0].shape[0]))\n",
    "    \n",
    "    # Get statistics\n",
    "    tmp_min_holder = np.min(data_holder, axis=0)\n",
    "    tmp_max_holder = np.max(data_holder, axis=0)\n",
    "    tmp_sum_holder = np.sum(data_holder, axis=0)\n",
    "    tmp_square_sum_holder = np.sum(np.square(data_holder), axis=0)\n",
    "\n",
    "    # Update the previous results\n",
    "    min_holder = np.minimum(min_holder, tmp_min_holder)\n",
    "    max_holder = np.maximum(max_holder, tmp_max_holder)\n",
    "    sum_holder += tmp_sum_holder\n",
    "    square_sum_holder += tmp_square_sum_holder\n",
    "    \n",
    "    # Update the batch_counter\n",
    "    print(\"Finishes processing batch {}\".format(batch_counter))\n",
    "    batch_counter += 1\n",
    "\n",
    "# Get a time stamp\n",
    "stamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    \n",
    "# Save the result\n",
    "with h5.File(output_address + 'statistics_{}_{}_{}_{}.h5'.format(tag, exp_name, run_num, stamp), 'w') as  h5file:\n",
    "    h5file.create_dataset(\"min_stack\", data=min_holder)\n",
    "    h5file.create_dataset(\"max_stack\", data=max_holder)\n",
    "    h5file.create_dataset(\"sum_stack\", data=sum_holder)\n",
    "    h5file.create_dataset(\"square_sum_stack\", data=square_sum_holder)\n",
    "    \n",
    "    # Get mean and std\n",
    "    mean_holder = sum_holder / float(pattern_num)\n",
    "    std_holder = np.sqrt(square_sum_holder / pattern_num - np.square(mean_holder))\n",
    "    std_holder *= np.sqrt(pattern_num) / np.sqrt(pattern_num - 1)\n",
    "    \n",
    "    # Save the results\n",
    "    h5file.create_dataset(\"pattern_num\", data= pattern_num)\n",
    "    h5file.create_dataset(\"mean_stack\", data=mean_holder)\n",
    "    h5file.create_dataset(\"std_stack\", data=std_holder)\n",
    "    \n",
    "    # Turn all the stack image into 2D patterns\n",
    "    h5file.create_dataset(\"min_2d\", data=det.image(nda_in=min_holder, evt=evt))\n",
    "    h5file.create_dataset(\"max_2d\", data=det.image(nda_in=max_holder, evt=evt))\n",
    "    h5file.create_dataset(\"sum_2d\", data=det.image(nda_in=sum_holder, evt=evt))\n",
    "    h5file.create_dataset(\"square_sum_2d\", data=det.image(nda_in=square_sum_holder, evt=evt))\n",
    "    h5file.create_dataset(\"mean_2d\", data=det.image(nda_in=mean_holder, evt=evt))\n",
    "    h5file.create_dataset(\"std_2d\", data=det.image(nda_in=std_holder, evt=evt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
